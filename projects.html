<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css">
    <title>About Me</title>
</head>
<a href="index.html">
    Click to Homepage
</a>
<body>
    <div>
        <img src="project.jpg" class="logos">
      

    </div class="project">
  
      <h3>Bank Campaign Prediction</h3>
      <p>Use of classification method as a machine learning tool in modelling a solution that can help marketing managers and their team in determining productive campaigns based on successful customer subscription of long-term deposit packages. Such solution would help improve efficiency of the campaigns by identifying the main features that affect campaign success, which translates to improved resource optimisation and quality selection process of potential buying customers. This study will provide a model or solution in curbing the following problems:
        •	Low productivity of campaigns using random selection of contacts.
        •	Campaigns can be time consuming
        •	High cost of resources in running campaigns
        Based on the problems listed above the following objectives has been set for this study to resolve these problems
        1.	Create a model for bank marketing campaigns to clearly explain and predict successful campaigns by determining whether a contact will sign up for a long-term deposit subscription with the bank.
        2.	Determine the relevant features that is required for a successful campaign to manage time and resources.
        
        </p>
      <p>Dataset was collected from UCI dataset repository with link
        <a href=" https://archive.ics.uci.edu/ml/datasets/bank+marketing">Click here for Dataset</a>
        The dataset used in this study is related with direct marketing campaigns of a Portuguese banking institution.
        Data Cleaning was conducted using Python, techniques like Normalisation of data variables for uniform scale, distribution plots of the data class to check for class imbalance, resampling of the datasets using over-sampling method to get a balanced class in this study to avoid loss if data in the case of under sampling (oversampling technique produced a better accuracy score for the model) and lastly feature selection techniques using recursive feature selecting technique was explored in this study to meet business needs.
    </p>
      <p>Data modelling for this study was done using K-Nearest Neighbor(KNN) and Adaboost Classifier(Decision tree base model) using Python  and two-class Neural Network using Azure machine learning studio. Dataset are divided into train and test splits and Models were fitted to train datasets to predict test dataset and achieve good precision models with good F1 score considering the class imbalance. Model was generated for both before and after feature selection with different number of features and metric scores .</p>
      <p>One of the business needs of this study is to determine the relevant features that is required for a successful campaign to manage time and resources. Hence, feature selection techniques were applied to the dataset using Recursive Feature Elimination with Cross Validation (RFECV) with 6 steps to remove 6 redundant features using LogisticRegression as extimator since class label is binary(categorical). Also, StratifiedKFold was used as cross validation technique to aid in preserving the percentage of samples for each class since class is imbalanced. The model created was able to predict if customer will subscribe to the campaign with an accuracy score of 84% with Adaboost ensemble learning. Python Notebook of the full code can be accessed here <a href= "https://colab.research.google.com/drive/1cDr6OlnxnNTse091H_ypcGxGbY0d5Ey4?authuser=1#scrollTo=240cee3e"> Click here</a> </p>
    </div>
    <div class="project">
      <h3>Sales Promotion Using Association Rule Mining Insights for Online Stores in United Kingdom</h3>
      <p>Association rule is an unsupervised learning where algorithm tries to learn data that are not labelled. This study will analyse online sales data particularly for customer orders in United Kingdom which has more records of orders in the dataset being evaluated.  This study would identify possible relationships between products ordered by customers and proffer effective association rules that would guide discount sales promotion for online stores.</p>
      <p>To achieve study objective, dataset was collected from UCI data repository with link below
        <a href= "https://archive.ics.uci.edu/ml/datasets/online+retail"> Click here for Dataset</a>
        The dataset being used is the Online Retail Dataset containing transactions made on a UK-based online retail store between the 1st of December 2010 and 9th of December 2011 for Customers all over the world
        Data preparation techniques was conducted on the dataset as missing values were identified in the dataset on the Description and customer id columns, hence rows with null values were dropped, reducing the total record of data from 541909 rows to 406829 rows.Furthermore, Invoice number column contains invoice numbers of customer orders that were later cancelled and could be identified with letter “C”. Cancelled orders won’t be needed in this analysis hence rows containing invoice number with a “C” in it were dropped reducing out data records to 397924 rows.In line with preparation of dataset in the required format for the algorithm, items purchased by customers were grouped by invoice number and multiplied the grouped data by quantity of items ordered. Unstack function was used to separate products into columns (each column represents an item) while the invoice number was set as index (each row contains details of products ordered for an invoice number). Further transformation was applied to the table to encode data into zeros and one, which is the required format for the apriori algorithm, hence a function was defined to set all values greater than or equal to one as 1(meaning items were purchased) while items with zero or less be classified as 0(meaning items were not purchased).</p>
      <p>Association rule mining can be implemented using python libraries like apyori or mlxtend that contains apriori function and association rule function. In this study mlxtend library was used. Apriori algorithm is the most used algorithm for association rule mining. It identifies the most frequent item sets in a transaction data and analyses relationships between the items using key measures: support confidence, and lift. To generate a frequent item set, apriori function imported from mlxtend library was applied to the prepared dataset that has been unstacked and encoded in the right format and below is the result of the analysis ordered by support in descending order (minimum support was set as 0.03).</p>
      <p>Sales analysis shows that sales increases towards the end of the year with a peak in November which is intuitively plausible as customers shop more in preparation of the festive period (Christmas and a new year). The month of February recorded the lowest number of sales which makes it a target month for sales promotion to boost sales. The hourly sales chart identifies high sales between 9 am to 3pm with a peak at noon which would inform sales promotion plans to intensify strategies at these times to achieve better sales. Efficient application of sales promotion techniques using these insights tends to improve sales of both peak and non-peak periods.In summeary, Considering the results of analysis done in this study, sales promotion is likely to be more efficient when applied at 12pm during the peak time of sales especially weekdays. Also, rewards for loyalty to top purchasing customers as identified in this study will encourage more orders. Top performing stock codes identified by the study should also be adequately stocked during sales promotion campaign. It is also recommended that Discounts for ROSES REGENCY TEACUP AND SAUCER should be promoted to customers who purchase GREEN REGENCY TEACUP AND SAUCER since the likelihood of buying the consequent is high when antecedent has been purchased. This should apply to other rules generated by the algorithm. Python Notebook for Full code can be seen using this link <a href= "https://colab.research.google.com/drive/19d9X6CnpVEDHPg6Nnv96N_XDtxImToAk?authuser=1"> Click here</a></p>
    </div>
    <div class="project">
        <h3>Sentiment Analysis and Text Mining for Sampled Hotel Restaurant and Bars Based on Lowest Reviews.</h3>
        <p>In this project, we would analyse a group of 30 least reviewed hotels in our dataset, narrow down to a specific hotel based on percentage of negative reviews identified and conduct sentiment analysis of hotel reviews for selected hotel to find out why reviews were low. This study will create word cloud that presents the most frequent words that customers use in their reviews and visualize the resulting reports using Bar plots, frequency plots and tables.</p>
        <p>Data Cleaning techniques applied includes:	
            <br>• Tokenization: This involves splitting the text into separate parts, called tokens.
            <br>• Removal of Stop words, punctuation, and special characters: Stop words are words such as articles, prepositions etc (e.g., ‘a’, ‘the’, ‘in’) which occur frequently but which aren’t particularly useful in text mining. RegexpTokenizer was used from NLTK (Natural Language Toolkit) library to transform characters like sentences into tokens (split sentences into words). It also defines a regular expression so that only alphanumeric characters are tokenized. 
            <br>• Convert all letters in a word to lower case
            <br>• Stemming: Stemming involves reducing words into a root form– this is useful because it reduces the number of unique tokens while preserving semantics (e.g., cleaned, cleaning and clean would all be reduced to clean. Stemming was used as an alternative to lemmatisation which is more difficult to use as it requires us to correctly specify the intended part of speech (lemma)of each word. 
            </p>
        <p> Sentiments intensity Analysis using SentimentIntensityAnalyzer within NLTK library which has a pre-trained model called VADER (Valence Aware Dictionary for Sentiment Reasoning) which can estimate both sentiment polarity (whether it is positive or negative) and intensity (how strongly positive or negative it is).Based on the objective of this study, which is to identify 30 Hotels from the study dataset and perform text mining technique and sentiment analysis on data selected, a new table was created for 30 selected hotel review records based on low frequency of reviews for these selected hotels, restaurants, and bars making it a total of 2689 records to analyse. Summary table above shows that out of 2689 reviews 1042 are unique reviews which means 60% of reviews are similar. <br> Also, the project shows that 30 hotels and restaurant are from 11 locations in Thailand.  Le Brooklyn Patong in Patong recorded the highest number of reviews (93) while the most frequent review is a bad review that occurred 10 times.
            Sentiment analysis was conducted on the sampled reviews and sentiment polarity of negative and positive reviews shows that most reviews were positive although, the density of positive sentiments distribution is more towards the left (right skewed) and fewer towards the extreme positive sentiment of 1. Also, the density of negative polarity score distribution is very scanty where few negative reviews are concentrated more on zero than towards the extreme negative point of 1. This was further depicted by the compound polarity score distribution, where scores lower than zero are negative sentiments and their level of intensity, and scores higher than zero are positive sentiments (Distribution was left skewed as expected).Further review of hotels, restaurants, and bars by percentage of negative reviews (reviews with compound less than or equal to zero) identifies Dada Yura Restaurant as the tourist accommodation with the highest percentage negative review hence this study will further analyse reviews of Dada Yura Restaurant to identify these negative review words for more insights. Moreso, analysis of percentage positive reviews (reviews with compound more than zero) showed that Chekhoff Restaurant and Bar had a 100% positive reviews, however this assumption was evaluated using text mining techniques to view frequency distribution of the positive reviews and corresponding word cloud.The word cloud and frequency distribution of negative reviews of Dada Yura Restaurant (refer to figure 3 and 4) depicted some insights which could better inform the restaurant management on what to improve. They are as follows:
           <br> •	Bad review about the staff in the restaurant
           <br> •	Restaurant appears Untidy and messy to some customers
           <br> •	Poor Service rendered by staff 
           <br> •	The food taste was horrible for some customers
            <br>It is also observed that some customers said nice things too about services and food especially dinner considering the word cloud of the positive reviews for the restaurant.
            </p>
        <p>In summary, the ability of text mining and sentiment analysis to provide good insights of customer opinions to businesses has been achieved in this study. Selection of hotels and restaurants based on lowest reviews as selection criteria provides great insights to why the reviews are low recommending what could be worked on to increase positive customer reviews based on generated word clouds and frequency distribution of review words in case study hotels and restaurant (Dada Yura restaurant in Patong selected based on highest percentage negative review and Chekhoff Restaurant and bar selected based on highest percentage positive review). These insights would be useful by management and decision makers of hotels, restaurants and bar in the study locations create better customer experience in tourism industry. Python Notebook for the full code of this project can be seen using this link <a href = "https://colab.research.google.com/drive/1URc_m3StNJQP3-0lENI89iMpdIviBHHd?authuser=1"> Click here</a></p>
      </div>
      <div class="project">
        <h3> ARTIFICIAL INTELLIGENCE FAIRNESS: METHODS TO DETECT AND MITIGATE BIAS</h3>
        <p>It is important to ensure that AI is not used to perpetuate existing biases or discrimination. This study therefore explored AI Fairness 360 (AIF360) Python library by IBM, that consists of fairness metrics and algorithms that can mitigate bias in machine learning workflow. .</p>
        <p>Study datasets were processed datasets from the AIF360 package namely adult census dataset, German scoring dataset and COMPAS recidivism dataset. These datasets were cleaned from null values, encoded for binary classification and normalised for unifrom variable scale. These datasets were analyzed with fairness metrics to detect bias in the training dataset</p>
        <p>Using AIF360 package, reweighing algorithm was implemented, and fairness and model performance were analyzed before and after implementation of the reweighing algorithm to examine its effect on improving fairness across groups. The study used Logistics regression classifier to train model for each study dataset, predict outcomes and evaluate model performance for the three study datasets, comparing the fairness metrics and balanced accuracy of the model before and after reweighing method was implemented. </p>
        <p>The study findings indicated that models created using the study dataset were biased against the unprivileged groups and reweighing method applied was able to significantly mitigate bias to create a fairer model for both the privileged and unprivileged group. Furthermore, the fairness-accuracy trade off was discussed in this study and the study was able to show using German dataset that fairness can also be achieved without significantly reducing model accuracy. Python Notebook containing the full code of this project can be seen with this link <a href= "https://colab.research.google.com/drive/1XZ7uXwUeN0ZeYfiEWOgr_mIeb-vXPSkL?authuser=1"> Click here</a></p>
      </div>
  </section>
  <footer>
    <p>&copy; 2023 My Data Science Portfolio. All rights reserved.</p>
  </footer>
